{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the test data filepath\n",
    "s3_path = os.path.join('test_data', 'allplayers.json')\n",
    "jsonfile = open(s3_path)\n",
    "contents = json.load(jsonfile)\n",
    "# Convert JSON to dataframe\n",
    "allplayers = pd.DataFrame.from_dict(contents)\n",
    "## Transform\n",
    "# Transpose dataframe\n",
    "allplayers = allplayers.T\n",
    "# Create a column for sleeper_id based on the index\n",
    "allplayers = allplayers.reset_index(names='id_sleeper')\n",
    "# Filter out inactive players\n",
    "allplayers = allplayers.loc[allplayers['status']!=\"Inactive\"]\n",
    "# Create a full name for the Defenses\n",
    "allplayers.loc[allplayers['position']==\"DEF\", 'full_name'] = allplayers.loc[\n",
    "    allplayers['position']==\"DEF\", 'first_name'\n",
    "    ] + \" \" + allplayers.loc[\n",
    "        allplayers['position']==\"DEF\", 'last_name'\n",
    "        ]\n",
    "# Select only relevant columns\n",
    "allplayers = allplayers[[\n",
    "    'id_sleeper',\n",
    "    'full_name', \n",
    "    'weight', 'height',\n",
    "    'birth_date', 'age', \n",
    "    'high_school', 'college',\n",
    "    'sport', 'years_exp', 'active', 'status',\n",
    "    'team', 'number', 'position', 'depth_chart_position', 'depth_chart_order',\n",
    "    'news_updated', 'injury_status', 'injury_body_part', 'injury_start_date', 'injury_notes', 'practice_description', 'practice_participation',\n",
    "]]\n",
    "# Set datatypes\n",
    "# Convert string columns\n",
    "cols_to_string = [\n",
    "    'id_sleeper',\n",
    "    'full_name', \n",
    "    'high_school', 'college',\n",
    "    'sport','active', 'status',\n",
    "    'team', 'number', 'position', 'depth_chart_position', 'depth_chart_order',\n",
    "    'news_updated', 'injury_status', 'injury_body_part', 'injury_start_date', 'injury_notes', 'practice_description', 'practice_participation'\n",
    "]\n",
    "for colName in cols_to_string:\n",
    "    allplayers[colName] = allplayers[colName].astype(str)\n",
    "# Convert float columns\n",
    "cols_to_float = [\n",
    "    'weight', 'height',\n",
    "    'age', \n",
    "    'years_exp',\n",
    "]\n",
    "for colName in cols_to_float:\n",
    "    allplayers[colName] = pd.to_numeric(allplayers[colName], errors='coerce')\n",
    "    allplayers[colName] = allplayers[colName].astype(float)\n",
    "# Convert datetime columns\n",
    "cols_to_datetime = [\n",
    "    'birth_date'\n",
    "]\n",
    "for colName in cols_to_datetime:\n",
    "    allplayers[colName] = pd.to_datetime(allplayers[colName], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read static data\n",
    "ids = pd.read_csv('test_data/lu_ids.csv')\n",
    "# Read other scraped data\n",
    "ourlads = pd.read_csv('test_data/ourlads.csv')\n",
    "sharks = pd.read_csv('test_data/sharks.csv', dtype={'Week':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create predictions dataset\n",
    "predictions = ids.merge(\n",
    "    sharks, how='inner', on='id_sharks'\n",
    ").merge(\n",
    "    ourlads, how = 'left', on='id_ourlads'\n",
    ")\n",
    "# Clean column names\n",
    "predictions = predictions.drop(columns=[\n",
    "    'id_ourlads', 'id_sharks', '#', 'Tm', 'Opp',\n",
    "])\n",
    "# Create a primary key\n",
    "predictions['index_predictions'] = predictions['id_sleeper'] + \"_\" + predictions['Week']\n",
    "# Drop NA values\n",
    "predictions = predictions.dropna(subset='index_predictions')\n",
    "# Drop duplicates\n",
    "predictions = predictions.drop_duplicates(subset='index_predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derive additional columns from others\n",
    "predictions.loc[predictions['PR']==True, 'pr_yd'] = 13\n",
    "predictions.loc[predictions['KR']==True, 'kr_yd'] = 19\n",
    "predictions['fgm_yds_over_30'] = predictions['30-39 FGM'] + predictions['40-49 FGM'] + predictions['50+ FGM']\n",
    "predictions.loc[(predictions['Pts Agn']<1), 'pts_allow_0'] = 1\n",
    "predictions.loc[(predictions['Pts Agn']>=1) & (predictions['Pts Agn']<7), 'pts_allow_1_6'] = 1\n",
    "predictions.loc[(predictions['Pts Agn']>=7) & (predictions['Pts Agn']<14), 'pts_allow_7_13'] = 1\n",
    "predictions.loc[(predictions['Pts Agn']>=14) & (predictions['Pts Agn']<21), 'pts_allow_14_20'] = 1\n",
    "predictions.loc[(predictions['Pts Agn']>=21) & (predictions['Pts Agn']<28), 'pts_allow_21_27'] = 1\n",
    "predictions.loc[(predictions['Pts Agn']>=28) & (predictions['Pts Agn']<35), 'pts_allow_28_34'] = 1\n",
    "predictions.loc[(predictions['Pts Agn']>=35), 'pts_allow_35p'] = 1\n",
    "predictions.loc[(predictions['Yds Allowed']<100), 'yds_allow_0_100'] = 1\n",
    "predictions.loc[(predictions['Yds Allowed']>=100) & (predictions['Yds Allowed']<200), 'yds_allow_100_199'] = 1\n",
    "predictions.loc[(predictions['Yds Allowed']>=200) & (predictions['Yds Allowed']<300), 'yds_allow_200_299'] = 1\n",
    "predictions.loc[(predictions['Yds Allowed']>=400) & (predictions['Yds Allowed']<450), 'yds_allow_400_449'] = 1\n",
    "predictions.loc[(predictions['Yds Allowed']>=450) & (predictions['Yds Allowed']<500), 'yds_allow_450_499'] = 1\n",
    "predictions.loc[(predictions['Yds Allowed']>=500) & (predictions['Yds Allowed']<550), 'yds_allow_500_549'] = 1\n",
    "predictions.loc[(predictions['Yds Allowed']>=550), 'yds_allow_550p'] = 1\n",
    "predictions.loc[(predictions['Rsh Yds']>=100) & (predictions['Rsh Yds']<200), 'bonus_rush_yd_100'] = 1\n",
    "predictions.loc[predictions['Rsh Yds']>=200, 'bonus_rush_yd_200'] = 1\n",
    "predictions.loc[(predictions['Rec Yds']>=100) & (predictions['Rec Yds']<200), 'bonus_rec_yd_100'] = 1\n",
    "predictions.loc[predictions['Rec Yds']>=200, 'bonus_rec_yd_200'] = 1\n",
    "predictions.loc[(predictions['Pass Yds']>=300) & (predictions['Pass Yds']<400), 'bonus_pass_yd_300'] = 1\n",
    "predictions.loc[predictions['Pass Yds']>=400, 'bonus_pass_yd_400'] = 1\n",
    "predictions['Rush and Rec Yds'] = predictions['Rsh Yds'] + predictions['Rec Yds']\n",
    "predictions.loc[predictions['Rush and Rec Yds']>=200, 'bonus_rush_rec_yd_200'] = 1\n",
    "\n",
    "# Rename columns\n",
    "predictions = predictions.rename(columns={\n",
    "    'Week':'week_of_season',\n",
    "    'Comp':'pass_cmp', 'Pass Yds':'pass_yd', 'Pass TDs':'pass_td', \n",
    "    'Int':'pass_int', \n",
    "    'Rush':'rush_att', 'Rsh Yds':'rush_yd', 'Rsh TDs':'rush_td', \n",
    "    'Fum':'fum_lost',\n",
    "    'Rec':'rec','Rec Yds':'rec_yd', 'Rec TDs':'rec_td', \n",
    "    'XPM':'xpm', 'FGM':'fgm', '10-19 FGM':'fgm_0_19','20-29 FGM':'fgm_20_29', '30-39 FGM':'fgm_30_39', '40-49 FGM':'fgm_40_49', '50+ FGM':'fgm_50p',\n",
    "    'Miss':'fgmiss', \n",
    "    'Scks':'sack', 'DefTD':'def_st_td', 'Safts':'safe',     \n",
    "})\n",
    "# Drop unnecessary columns which sharks has but sleeper lacks\n",
    "predictions = predictions.drop(columns=[\n",
    "    'Att', '0-9 Pass TDs', '10-19 Pass TDs', '20-29 Pass TDs', '30-39 Pass TDs', '40-49 Pass TDs', '50+ Pass TDs', 'Sck', \n",
    "    '0-9 Rsh TDs', '10-19 Rsh TDs', '20-29 Rsh TDs', '30-39 Rsh TDs', '40-49 Rsh TDs', '50+ Rsh TDs',\n",
    "    '>= 50 yd', '>= 100 yd','0-9 Rec TDs', '10-19 Rec TDs', '20-29 Rec TDs', '30-39 Rec TDs','40-49 Rec TDs', '50+ Rec TDs',\n",
    "    'Tgt', 'RZ Tgt', \n",
    "    'Kick Ret Yds','PR', 'KR',\n",
    "    'XPA','FGA', \n",
    "    'Punts','Punt Yds', 'Punts Inside 20', \n",
    "    'Yds Allowed', 'Pts Agn', \n",
    "    'Rush and Rec Yds'\n",
    "])\n",
    "# Set to zero predictions which sharks lacks but sleeper has\n",
    "for colName in [\n",
    "    'pass_2pt', 'rush_2pt', 'rec_2pt', 'xpmiss', \n",
    "    'int', 'fum_rec', 'blk_kick', 'ff','def_st_ff','def_st_fum_rec',\n",
    "    'def_td','def_3_and_out','def_2pt',\n",
    "    'st_fum_rec','st_ff','st_td',\n",
    "    'fum','fum_rec_td',\n",
    "]:\n",
    "    predictions[colName] = 0\n",
    "    # Change each column to float64 data type\n",
    "    predictions[colName] = predictions[colName].astype('float64')\n",
    "# Set NA values to zero\n",
    "predictions = predictions.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move a couple of the defensive int and fumble scores to the proper column\n",
    "defensive_ids = [\n",
    "    'MIN','KC','DEN','CIN','CHI','TEN','NYG','SF','PHI','BUF','DET','MIA','GB','NO','LAR','JAX','CAR','ATL','CLE','TB','LAC','WAS','DAL','NYJ','LV','SEA','ARI','IND','PIT','BAL','NE','HOU',\n",
    "]\n",
    "predictions.loc[predictions['id_sleeper'].isin(defensive_ids), 'int'] = predictions.loc[predictions['id_sleeper'].isin(defensive_ids), 'pass_int']\n",
    "predictions.loc[predictions['id_sleeper'].isin(defensive_ids), 'pass_int'] = 0\n",
    "predictions.loc[predictions['id_sleeper'].isin(defensive_ids), 'fum'] = predictions.loc[predictions['id_sleeper'].isin(defensive_ids), 'fum_lost']\n",
    "predictions.loc[predictions['id_sleeper'].isin(defensive_ids), 'fum_lost'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tidy up columns\n",
    "predictions = predictions[[\n",
    "    'index_predictions', 'id_sleeper', 'week_of_season', 'pass_cmp', 'pass_yd',\n",
    "    'pass_td', 'pass_int', 'rush_att', 'rush_yd', 'rush_td', 'fum_lost',\n",
    "    'rec', 'rec_yd', 'rec_td', 'xpm', 'fgm', 'fgm_0_19', 'fgm_20_29',\n",
    "    'fgm_30_39', 'fgm_40_49', 'fgm_50p', 'fgmiss', 'sack', 'def_st_td',\n",
    "    'safe', 'pr_yd', 'kr_yd', 'fgm_yds_over_30', 'pts_allow_0',\n",
    "    'pts_allow_1_6', 'pts_allow_7_13', 'pts_allow_14_20', 'pts_allow_21_27',\n",
    "    'pts_allow_28_34', 'pts_allow_35p', 'yds_allow_0_100',\n",
    "    'yds_allow_100_199', 'yds_allow_200_299', 'yds_allow_400_449',\n",
    "    'yds_allow_450_499', 'yds_allow_500_549', 'yds_allow_550p',\n",
    "    'bonus_rush_yd_100', 'bonus_rush_yd_200', 'bonus_rec_yd_100',\n",
    "    'bonus_rec_yd_200', 'bonus_pass_yd_300', 'bonus_pass_yd_400',\n",
    "    'bonus_rush_rec_yd_200', 'pass_2pt', 'rush_2pt',\n",
    "    'rec_2pt', 'xpmiss', 'int', 'fum_rec', 'blk_kick', 'ff', 'def_st_ff',\n",
    "    'def_st_fum_rec', 'def_td', 'def_3_and_out', 'def_2pt', 'st_fum_rec',\n",
    "    'st_ff', 'st_td', 'fum', 'fum_rec_td'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set predictions datatypes\n",
    "# String datatypes\n",
    "cols_to_string_predictions = [\n",
    "    'index_predictions', 'id_sleeper', 'week_of_season',\n",
    "]\n",
    "for colName in cols_to_string_predictions:\n",
    "    predictions[colName] = predictions[colName].astype(str)\n",
    "# Float datatypes\n",
    "cols_to_float_predictions = [\n",
    "    'pass_cmp', 'pass_yd',\n",
    "    'pass_td', 'pass_int', 'rush_att', 'rush_yd', 'rush_td', 'fum_lost',\n",
    "    'rec', 'rec_yd', 'rec_td', 'xpm', 'fgm', 'fgm_0_19', 'fgm_20_29',\n",
    "    'fgm_30_39', 'fgm_40_49', 'fgm_50p', 'fgmiss', 'sack', 'def_st_td',\n",
    "    'safe', 'pr_yd', 'kr_yd', 'fgm_yds_over_30', 'pts_allow_0',\n",
    "    'pts_allow_1_6', 'pts_allow_7_13', 'pts_allow_14_20', 'pts_allow_21_27',\n",
    "    'pts_allow_28_34', 'pts_allow_35p', 'yds_allow_0_100',\n",
    "    'yds_allow_100_199', 'yds_allow_200_299', 'yds_allow_400_449',\n",
    "    'yds_allow_450_499', 'yds_allow_500_549', 'yds_allow_550p',\n",
    "    'bonus_rush_yd_100', 'bonus_rush_yd_200', 'bonus_rec_yd_100',\n",
    "    'bonus_rec_yd_200', 'bonus_pass_yd_300', 'bonus_pass_yd_400',\n",
    "    'bonus_rush_rec_yd_200', 'pass_2pt', 'rush_2pt',\n",
    "    'rec_2pt', 'xpmiss', 'int', 'fum_rec', 'blk_kick', 'ff', 'def_st_ff',\n",
    "    'def_st_fum_rec', 'def_td', 'def_3_and_out', 'def_2pt', 'st_fum_rec',\n",
    "    'st_ff', 'st_td', 'fum', 'fum_rec_td'\n",
    "]\n",
    "for colName in cols_to_float_predictions:\n",
    "    predictions[colName] = pd.to_numeric(predictions[colName], errors='coerce')\n",
    "    predictions[colName] = predictions[colName].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "allplayers.to_csv('test_data/rds_players.csv', index=False)\n",
    "predictions.to_csv('test_data/rds_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.3 ('fnfl2024')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "33dbe7c72db16b281083c7de59ed8ec8f22d2824957f89e4bfb828dc6fc75088"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
